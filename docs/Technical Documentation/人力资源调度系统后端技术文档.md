# 人力资源调度系统后端技术文档

## 文档概述

本文档详细描述了人力资源调度系统的后端技术架构、API接口设计、数据库设计、部署流程和安全规范等核心技术内容，为系统开发、部署和运维提供完整的技术指导。

**文档版本**：v1.0  
**创建日期**：2024年  
**适用范围**：园林绿化施工公司人力资源调度系统后端开发  
**技术栈**：Python FastAPI + PostgreSQL + Redis + Docker

## 系统概述

### 系统定位
本系统专注于构建智能化、可视化的资源调度管理平台，核心功能包括：
- **智能化资源调度管理**：基于AI算法的智能匹配和优化调度
- **全流程资源风险管控**：实时监控、预警和应急响应机制
- **数据驱动的资源分配评估**：基于数据分析的配置评估和决策支持

### 系统特色
- ❌ **不包含考勤功能**：专注于资源调度，不涉及打卡工时管理
- 🔗 **预留ERP集成接口**：为未来系统集成预留标准化接口
- 🎯 **模块化架构设计**：确保系统扩展性和可维护性
- 🤖 **AI算法集成**：内置机器学习算法引擎，支持智能匹配和预测分析

### 系统功能边界

#### 核心功能范围
本系统专注于人力资源调度管理的核心功能：
- **调度时长设置**：为调度决策提供时间规划依据
- **时间规划**：合理安排人员在项目中的时间分配
- **冲突解决**：识别和解决时间冲突、资源冲突
- **资源优化**：基于调度需求进行人员配置优化

#### 明确排除的功能
以下功能明确不在本系统范围内：
- **绩效管理**：员工绩效考核、评价、奖惩等
- **考勤打卡**：上下班打卡、考勤统计等
- **工时统计**：实际工作时间记录和统计
- **薪资计算**：工资核算、奖金分配等

**重要说明**：系统中所有时间相关数据（调度时长、时间规划等）仅服务于调度系统的核心功能，不用于考勤、工时统计或薪资计算等用途。

## 1. 系统架构设计

### 1.1 整体架构

#### 架构模式
- **架构类型**：微服务架构 + 前后端分离
- **部署方式**：容器化部署（Docker + Kubernetes）
- **通信协议**：HTTP/HTTPS + WebSocket（实时通信）
- **数据格式**：JSON + Protocol Buffers（内部服务通信）

#### 系统分层
```
┌─────────────────────────────────────────┐
│              前端层 (React)              │
├─────────────────────────────────────────┤
│            API网关层 (Nginx)            │
├─────────────────────────────────────────┤
│          应用服务层 (FastAPI)           │
├─────────────────────────────────────────┤
│         业务逻辑层 (Service)            │
├─────────────────────────────────────────┤
│         数据访问层 (Repository)         │
├─────────────────────────────────────────┤
│    数据存储层 (PostgreSQL + Redis)     │
└─────────────────────────────────────────┘
```

### 1.2 技术栈选型

#### 后端核心技术栈
- **Web框架**：Python FastAPI 0.100+
  - 高性能异步框架
  - 自动生成OpenAPI文档
  - 内置数据验证和序列化
  - 类型提示支持
- **数据库**：PostgreSQL 14+
  - 完善的事务支持与ACID特性
  - 强大的JSON/JSONB数据类型支持
  - 丰富的扩展功能（全文检索、GIS地理信息）
  - 与Python生态高度兼容
- **缓存系统**：Redis 7+
  - 会话管理
  - 数据缓存
  - 消息队列
  - 分布式锁
- **消息队列**：Celery + Redis
  - 异步任务处理
  - 定时任务调度
  - 任务监控和管理
- **AI算法库**：
  - scikit-learn：机器学习算法
  - pandas：数据处理和分析
  - numpy：数值计算
  - TensorFlow/PyTorch：深度学习（可选）

#### 系统集成技术
- **容器化**：Docker + Docker Compose
- **编排工具**：Kubernetes（生产环境）
- **API网关**：Nginx + 反向代理
- **监控系统**：Prometheus + Grafana
- **日志管理**：ELK Stack（Elasticsearch + Logstash + Kibana）

### 1.3 微服务模块划分

#### 核心业务服务
1. **用户认证服务** (auth-service)
   - 用户登录/登出
   - JWT Token管理
   - 权限验证
   - 角色管理

2. **人员管理服务** (personnel-service)
   - 人员信息管理
   - 技能档案管理
   - 组织架构管理
   - 人员可用性管理

3. **项目管理服务** (project-service)
   - 项目信息管理
   - 项目需求管理
   - 项目进度跟踪
   - 项目资源分配

4. **智能调度服务** (scheduling-service)
   - 调度计划管理
   - 冲突检测和解决
   - 调度优化算法
   - 调度历史记录

5. **AI算法服务** (ai-service)
   - 智能匹配算法
   - 预测分析模型
   - 优化建议生成
   - 模型训练和更新

6. **风险管控服务** (risk-service)
   - 风险识别和监控
   - 预警规则管理
   - 应急响应处理
   - 风险数据分析

7. **数据分析服务** (analytics-service)
   - 配置评估分析
   - 趋势预测分析
   - 决策支持数据
   - 报表生成

8. **通知服务** (notification-service)
   - 消息推送
   - 邮件通知
   - 短信通知
   - 系统公告

#### 基础设施服务
1. **文件服务** (file-service)
   - 文件上传/下载
   - 文件存储管理
   - 图片处理
   - 文档管理

2. **配置服务** (config-service)
   - 系统配置管理
   - 参数配置
   - 功能开关
   - 环境配置

3. **日志服务** (logging-service)
   - 操作日志记录
   - 审计日志管理
   - 日志查询和分析
   - 日志归档

### 1.4 性能指标要求

#### 响应性能
- **API响应时间**：< 300ms（95%请求）
- **页面加载时间**：< 2秒
- **数据库查询**：复杂查询 < 500ms，简单查询 < 100ms
- **AI算法执行**：智能匹配 < 1秒，预测分析 < 3秒

#### 并发性能
- **并发用户数**：支持200+用户同时在线
- **API并发请求**：1000 QPS
- **数据库连接**：支持100+并发连接
- **消息队列处理**：1000 msg/s

#### 可用性要求
- **系统可用性**：99.9%以上
- **服务恢复时间**：< 5分钟
- **数据备份频率**：每日全量备份，实时增量备份
- **故障检测时间**：< 1分钟

## 2. API接口设计

### 2.1 API设计原则

#### RESTful设计风格
- 使用HTTP动词表示操作类型（GET、POST、PUT、DELETE、PATCH）
- 使用名词表示资源
- 使用HTTP状态码表示操作结果
- 统一的URL结构和命名规范

#### 接口规范
- **基础URL**：`https://api.hrscheduling.com/v1`
- **认证方式**：JWT Token + OAuth 2.0
- **数据格式**：JSON
- **字符编码**：UTF-8
- **版本控制**：URL路径版本控制（/v1、/v2）

### 2.2 通用响应格式

#### 成功响应格式
```json
{
  "code": 200,
  "message": "操作成功",
  "data": {},
  "timestamp": "2024-01-01T12:00:00Z",
  "request_id": "uuid"
}
```

#### 分页响应格式
```json
{
  "code": 200,
  "message": "查询成功",
  "data": {
    "items": [],
    "total": 100,
    "page": 1,
    "size": 20,
    "pages": 5
  },
  "timestamp": "2024-01-01T12:00:00Z",
  "request_id": "uuid"
}
```

#### 错误响应格式
```json
{
  "code": 400,
  "message": "请求参数错误",
  "error": {
    "type": "ValidationError",
    "details": [
      {
        "field": "email",
        "message": "邮箱格式不正确"
      }
    ]
  },
  "timestamp": "2024-01-01T12:00:00Z",
  "request_id": "uuid"
}
```

### 2.3 核心API接口

#### 2.3.1 认证授权接口

**用户登录**
```
POST /api/v1/auth/login
```
请求体：
```json
{
  "username": "string",
  "password": "string",
  "remember_me": "boolean"
}
```
响应：
```json
{
  "code": 200,
  "data": {
    "access_token": "jwt_token",
    "refresh_token": "refresh_token",
    "expires_in": 3600,
    "user_info": {
      "id": "string",
      "username": "string",
      "email": "string",
      "roles": ["string"]
    }
  }
}
```

**Token刷新**
```
POST /api/v1/auth/refresh
```

**用户登出**
```
POST /api/v1/auth/logout
```

#### 2.3.2 人员管理接口

**获取人员列表**
```
GET /api/v1/personnel?page=1&size=20&search=keyword&department=dept_id
```

**创建人员**
```
POST /api/v1/personnel
```
请求体：
```json
{
  "name": "string",
  "employee_id": "string",
  "email": "string",
  "phone": "string",
  "department_id": "string",
  "position": "string",
  "skills": [
    {
      "skill_type": "string",
      "skill_level": "string",
      "certification": "string"
    }
  ],
  "availability": {
    "work_days": ["monday", "tuesday"],
    "work_hours": {
      "start": "09:00",
      "end": "18:00"
    }
  }
}
```

**更新人员信息**
```
PUT /api/v1/personnel/{personnel_id}
```

**删除人员**
```
DELETE /api/v1/personnel/{personnel_id}
```

**获取人员技能**
```
GET /api/v1/personnel/{personnel_id}/skills
```

#### 2.3.3 项目管理接口

**获取项目列表**
```
GET /api/v1/projects?page=1&size=20&status=active&search=keyword
```

**创建项目**
```
POST /api/v1/projects
```
请求体：
```json
{
  "name": "string",
  "description": "string",
  "client_id": "string",
  "start_date": "2024-01-01",
  "end_date": "2024-12-31",
  "location": "string",
  "requirements": {
    "personnel_count": 10,
    "skill_requirements": [
      {
        "skill_type": "string",
        "skill_level": "string",
        "required_count": 2
      }
    ],
    "work_schedule": {
      "work_days": ["monday", "tuesday"],
      "work_hours": {
        "start": "08:00",
        "end": "17:00"
      }
    }
  }
}
```

**更新项目**
```
PUT /api/v1/projects/{project_id}
```

**获取项目人员**
```
GET /api/v1/projects/{project_id}/personnel
```

**分配人员到项目**
```
POST /api/v1/projects/{project_id}/personnel
```

#### 2.3.4 智能调度接口

**获取调度列表**
```
GET /api/v1/schedules?page=1&size=20&project_id=id&status=pending
```

**创建调度申请**
```
POST /api/v1/schedules
```
请求体：
```json
{
  "project_id": "string",
  "personnel_id": "string",
  "schedule_date": "2024-01-01",
  "work_hours": {
    "start": "08:00",
    "end": "17:00"
  },
  "role": "string",
  "notes": "string"
}
```

**AI智能匹配**
```
POST /api/v1/schedules/ai-match
```
请求体：
```json
{
  "project_id": "string",
  "requirements": {
    "skill_types": ["string"],
    "skill_levels": ["string"],
    "personnel_count": 5,
    "work_location": "string",
    "time_range": {
      "start_date": "2024-01-01",
      "end_date": "2024-01-31"
    }
  },
  "preferences": {
    "priority_factors": ["skill_match", "availability", "location"],
    "exclude_personnel": ["string"]
  }
}
```

**冲突检测**
```
GET /api/v1/schedules/conflicts?personnel_id=id&date_range=2024-01-01,2024-01-31
```

**调度优化建议**
```
GET /api/v1/schedules/optimization-suggestions?project_id=id
```

#### 2.3.5 风险管控接口

**获取风险监控数据**
```
GET /api/v1/risk/monitoring?type=all&time_range=7d
```

**风险识别分析**
```
POST /api/v1/risk/identification
```
请求体：
```json
{
  "analysis_type": "schedule_risk",
  "target_id": "string",
  "parameters": {
    "time_range": {
      "start_date": "2024-01-01",
      "end_date": "2024-01-31"
    },
    "risk_factors": ["personnel_shortage", "skill_mismatch"]
  }
}
```

**获取风险预警**
```
GET /api/v1/risk/alerts?status=active&severity=high
```

**应急响应处理**
```
POST /api/v1/risk/emergency-response
```

#### 2.3.6 数据分析接口

**资源配置评估**
```
GET /api/v1/analytics/configuration-assessment?project_id=id&time_range=30d
```

**预测分析**
```
POST /api/v1/analytics/prediction
```
请求体：
```json
{
  "prediction_type": "resource_demand",
  "time_horizon": "30d",
  "parameters": {
    "historical_data_range": "90d",
    "factors": ["seasonal", "project_type", "skill_demand"]
  }
}
```

**决策支持数据**
```
GET /api/v1/analytics/decision-support?analysis_type=resource_optimization
```

### 2.4 认证和授权

#### JWT Token认证
- **Token类型**：Bearer Token
- **Token有效期**：Access Token 1小时，Refresh Token 7天
- **Token刷新**：自动刷新机制
- **Token存储**：Redis缓存

#### 权限控制
- **权限模型**：RBAC（基于角色的访问控制）
- **权限粒度**：接口级别 + 数据级别
- **权限验证**：装饰器 + 中间件
- **权限缓存**：Redis缓存权限信息

#### 安全机制
- **请求签名**：关键接口使用HMAC签名
- **频率限制**：API调用频率限制
- **IP白名单**：敏感接口IP访问控制
- **审计日志**：所有API调用记录审计日志

### 2.5 错误处理

#### HTTP状态码
- **200 OK**：请求成功
- **201 Created**：资源创建成功
- **400 Bad Request**：请求参数错误
- **401 Unauthorized**：未授权访问
- **403 Forbidden**：权限不足
- **404 Not Found**：资源不存在
- **409 Conflict**：资源冲突
- **422 Unprocessable Entity**：数据验证失败
- **429 Too Many Requests**：请求频率超限
- **500 Internal Server Error**：服务器内部错误

#### 错误码定义
```python
class ErrorCode:
    # 通用错误码
    SUCCESS = 200
    BAD_REQUEST = 400
    UNAUTHORIZED = 401
    FORBIDDEN = 403
    NOT_FOUND = 404
    
    # 业务错误码
    PERSONNEL_NOT_FOUND = 1001
    PROJECT_NOT_FOUND = 1002
    SCHEDULE_CONFLICT = 1003
    SKILL_MISMATCH = 1004
    AI_SERVICE_ERROR = 1005
    RISK_THRESHOLD_EXCEEDED = 1006
```

## 3. 数据库设计

### 3.1 数据库选型

#### PostgreSQL优势
- **ACID事务支持**：确保数据一致性
- **JSON/JSONB支持**：灵活存储半结构化数据
- **全文检索**：内置全文搜索功能
- **扩展性**：丰富的扩展插件
- **性能优化**：查询优化器和索引支持

#### 数据库配置
- **版本**：PostgreSQL 14+
- **字符集**：UTF-8
- **时区**：UTC
- **连接池**：PgBouncer
- **备份策略**：WAL归档 + 定期全量备份

### 3.2 核心数据表设计

#### 3.2.1 用户和权限表

**用户表 (users)**
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(100),
    phone VARCHAR(20),
    avatar_url VARCHAR(255),
    is_active BOOLEAN DEFAULT true,
    is_superuser BOOLEAN DEFAULT false,
    last_login_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**角色表 (roles)**
```sql
CREATE TABLE roles (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(50) UNIQUE NOT NULL,
    description TEXT,
    permissions JSONB,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**用户角色关联表 (user_roles)**
```sql
CREATE TABLE user_roles (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    role_id UUID REFERENCES roles(id) ON DELETE CASCADE,
    assigned_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    assigned_by UUID REFERENCES users(id),
    UNIQUE(user_id, role_id)
);
```

#### 3.2.2 组织架构表

**组织架构表 (organizations)**
```sql
CREATE TABLE organizations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    code VARCHAR(50) UNIQUE,
    type VARCHAR(20) NOT NULL, -- company, region, department, team
    parent_id UUID REFERENCES organizations(id),
    level INTEGER NOT NULL DEFAULT 1,
    path VARCHAR(500), -- 层级路径，如 /1/2/3/
    manager_id UUID REFERENCES users(id),
    description TEXT,
    contact_info JSONB,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### 3.2.3 人员管理表

**人员档案表 (personnel)**
```sql
CREATE TABLE personnel (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    employee_id VARCHAR(50) UNIQUE NOT NULL,
    name VARCHAR(100) NOT NULL,
    gender VARCHAR(10),
    birth_date DATE,
    id_card VARCHAR(20),
    phone VARCHAR(20),
    email VARCHAR(100),
    address TEXT,
    emergency_contact JSONB,
    organization_id UUID REFERENCES organizations(id),
    position VARCHAR(100),
    employment_type VARCHAR(20), -- full_time, part_time, contract
    hire_date DATE,
    skills JSONB, -- 技能信息
    certifications JSONB, -- 证书信息
    availability JSONB, -- 可用性信息
    status VARCHAR(20) DEFAULT 'active', -- active, inactive, on_leave
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**技能字典表 (skill_types)**
```sql
CREATE TABLE skill_types (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    category VARCHAR(50),
    description TEXT,
    levels JSONB, -- 技能等级定义
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### 3.2.4 项目管理表

**项目表 (projects)**
```sql
CREATE TABLE projects (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(200) NOT NULL,
    code VARCHAR(50) UNIQUE,
    description TEXT,
    client_id UUID,
    project_manager_id UUID REFERENCES personnel(id),
    start_date DATE NOT NULL,
    end_date DATE NOT NULL,
    location JSONB, -- 项目地点信息
    requirements JSONB, -- 人员需求信息
    budget DECIMAL(15,2),
    status VARCHAR(20) DEFAULT 'planning', -- planning, active, completed, cancelled
    priority VARCHAR(10) DEFAULT 'medium', -- low, medium, high, urgent
    tags JSONB,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**客户表 (clients)**
```sql
CREATE TABLE clients (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(200) NOT NULL,
    code VARCHAR(50) UNIQUE,
    contact_person VARCHAR(100),
    phone VARCHAR(20),
    email VARCHAR(100),
    address TEXT,
    company_info JSONB,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### 3.2.5 调度管理表

**调度记录表 (schedules)**
```sql
CREATE TABLE schedules (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    project_id UUID REFERENCES projects(id) NOT NULL,
    personnel_id UUID REFERENCES personnel(id) NOT NULL,
    schedule_date DATE NOT NULL,
    start_time TIME NOT NULL,
    end_time TIME NOT NULL,
    role VARCHAR(100),
    work_location JSONB,
    status VARCHAR(20) DEFAULT 'pending', -- pending, approved, rejected, completed
    notes TEXT,
    created_by UUID REFERENCES users(id),
    approved_by UUID REFERENCES users(id),
    approved_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(personnel_id, schedule_date, start_time)
);
```

**AI匹配结果表 (ai_matching_results)**
```sql
CREATE TABLE ai_matching_results (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    request_id UUID NOT NULL,
    project_id UUID REFERENCES projects(id),
    personnel_id UUID REFERENCES personnel(id),
    match_score DECIMAL(5,2), -- 匹配分数 0-100
    match_factors JSONB, -- 匹配因子详情
    recommendation_reason TEXT,
    algorithm_version VARCHAR(20),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### 3.2.6 风险管控表

**风险识别记录表 (risk_identifications)**
```sql
CREATE TABLE risk_identifications (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    risk_type VARCHAR(50) NOT NULL,
    risk_level VARCHAR(20) NOT NULL, -- low, medium, high, critical
    target_type VARCHAR(50), -- project, personnel, schedule
    target_id UUID,
    description TEXT,
    risk_factors JSONB,
    probability DECIMAL(5,2), -- 风险概率 0-100
    impact_score DECIMAL(5,2), -- 影响分数 0-100
    mitigation_suggestions JSONB,
    status VARCHAR(20) DEFAULT 'active', -- active, resolved, ignored
    detected_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**风险预警规则表 (risk_alert_rules)**
```sql
CREATE TABLE risk_alert_rules (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    risk_type VARCHAR(50) NOT NULL,
    conditions JSONB NOT NULL, -- 触发条件
    threshold_config JSONB, -- 阈值配置
    alert_level VARCHAR(20) NOT NULL, -- info, warning, error, critical
    notification_config JSONB, -- 通知配置
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

#### 3.2.7 数据分析表

**配置评估结果表 (configuration_assessments)**
```sql
CREATE TABLE configuration_assessments (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    assessment_type VARCHAR(50) NOT NULL,
    target_id UUID,
    assessment_date DATE NOT NULL,
    metrics JSONB NOT NULL, -- 评估指标
    scores JSONB NOT NULL, -- 评估分数
    recommendations JSONB, -- 改进建议
    baseline_comparison JSONB, -- 基准对比
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

**预测分析数据表 (predictive_analysis_data)**
```sql
CREATE TABLE predictive_analysis_data (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    analysis_type VARCHAR(50) NOT NULL,
    prediction_target VARCHAR(100) NOT NULL,
    time_horizon VARCHAR(20), -- 预测时间范围
    input_data JSONB NOT NULL,
    prediction_results JSONB NOT NULL,
    confidence_level DECIMAL(5,2), -- 置信度
    model_version VARCHAR(20),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

### 3.3 索引设计

#### 3.3.1 主要索引
```sql
-- 用户表索引
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_is_active ON users(is_active);

-- 人员表索引
CREATE INDEX idx_personnel_employee_id ON personnel(employee_id);
CREATE INDEX idx_personnel_organization_id ON personnel(organization_id);
CREATE INDEX idx_personnel_status ON personnel(status);
CREATE INDEX idx_personnel_skills ON personnel USING GIN(skills);

-- 项目表索引
CREATE INDEX idx_projects_status ON projects(status);
CREATE INDEX idx_projects_start_date ON projects(start_date);
CREATE INDEX idx_projects_end_date ON projects(end_date);
CREATE INDEX idx_projects_client_id ON projects(client_id);

-- 调度表索引
CREATE INDEX idx_schedules_project_id ON schedules(project_id);
CREATE INDEX idx_schedules_personnel_id ON schedules(personnel_id);
CREATE INDEX idx_schedules_date ON schedules(schedule_date);
CREATE INDEX idx_schedules_status ON schedules(status);
CREATE INDEX idx_schedules_personnel_date ON schedules(personnel_id, schedule_date);

-- 风险表索引
CREATE INDEX idx_risk_identifications_type ON risk_identifications(risk_type);
CREATE INDEX idx_risk_identifications_level ON risk_identifications(risk_level);
CREATE INDEX idx_risk_identifications_target ON risk_identifications(target_type, target_id);
CREATE INDEX idx_risk_identifications_detected_at ON risk_identifications(detected_at);
```

#### 3.3.2 复合索引
```sql
-- 调度查询优化
CREATE INDEX idx_schedules_project_date_status ON schedules(project_id, schedule_date, status);
CREATE INDEX idx_schedules_personnel_date_status ON schedules(personnel_id, schedule_date, status);

-- 风险监控优化
CREATE INDEX idx_risk_type_level_status ON risk_identifications(risk_type, risk_level, status);

-- AI匹配结果优化
CREATE INDEX idx_ai_matching_request_score ON ai_matching_results(request_id, match_score DESC);
```

### 3.4 数据库优化

#### 3.4.1 查询优化
- **使用EXPLAIN分析查询计划**
- **避免N+1查询问题**
- **使用JOIN代替子查询**
- **合理使用LIMIT和OFFSET**
- **利用CTE和窗口函数**

#### 3.4.2 JSONB优化
```sql
-- 为JSONB字段创建GIN索引
CREATE INDEX idx_personnel_skills_gin ON personnel USING GIN(skills);
CREATE INDEX idx_projects_requirements_gin ON projects USING GIN(requirements);

-- JSONB查询示例
SELECT * FROM personnel 
WHERE skills @> '[{"skill_type": "园林设计", "skill_level": "高级"}]';
```

#### 3.4.3 分区表设计
```sql
-- 按时间分区的调度历史表
CREATE TABLE schedule_history (
    id UUID,
    project_id UUID,
    personnel_id UUID,
    schedule_date DATE,
    -- 其他字段...
    created_at TIMESTAMP WITH TIME ZONE
) PARTITION BY RANGE (schedule_date);

-- 创建分区
CREATE TABLE schedule_history_2024_q1 PARTITION OF schedule_history
FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');
```

## 4. 安全规范

### 4.1 数据安全

#### 4.1.1 数据加密
- **传输加密**：HTTPS/TLS 1.3
- **存储加密**：数据库字段级加密
- **密码加密**：bcrypt + salt
- **敏感数据**：AES-256加密存储

#### 4.1.2 数据脱敏
```python
# 敏感数据脱敏示例
def mask_phone(phone: str) -> str:
    """手机号脱敏"""
    if len(phone) >= 11:
        return phone[:3] + '****' + phone[-4:]
    return phone

def mask_id_card(id_card: str) -> str:
    """身份证号脱敏"""
    if len(id_card) >= 18:
        return id_card[:6] + '********' + id_card[-4:]
    return id_card
```

#### 4.1.3 数据备份安全
- **备份加密**：备份文件AES加密
- **访问控制**：备份文件访问权限控制
- **异地备份**：多地域备份存储
- **备份验证**：定期验证备份完整性

### 4.2 接口安全

#### 4.2.1 认证机制
```python
# JWT Token配置
JWT_CONFIG = {
    'algorithm': 'HS256',
    'access_token_expire_minutes': 60,
    'refresh_token_expire_days': 7,
    'secret_key': os.getenv('JWT_SECRET_KEY'),
    'issuer': 'hr-scheduling-system',
    'audience': 'hr-scheduling-client'
}
```

#### 4.2.2 API安全防护
```python
# 频率限制装饰器
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/v1/auth/login")
@limiter.limit("5/minute")
async def login(request: Request, user_data: UserLogin):
    # 登录逻辑
    pass

# 请求签名验证
def verify_signature(request: Request) -> bool:
    """验证请求签名"""
    signature = request.headers.get('X-Signature')
    timestamp = request.headers.get('X-Timestamp')
    
    # 验证时间戳（防重放攻击）
    if abs(time.time() - int(timestamp)) > 300:  # 5分钟
        return False
    
    # 验证签名
    expected_signature = generate_signature(request.body, timestamp)
    return hmac.compare_digest(signature, expected_signature)
```

#### 4.2.3 输入验证
```python
from pydantic import BaseModel, validator
from typing import Optional

class PersonnelCreate(BaseModel):
    name: str
    email: str
    phone: Optional[str]
    
    @validator('name')
    def validate_name(cls, v):
        if not v or len(v.strip()) < 2:
            raise ValueError('姓名长度不能少于2个字符')
        return v.strip()
    
    @validator('email')
    def validate_email(cls, v):
        import re
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if not re.match(pattern, v):
            raise ValueError('邮箱格式不正确')
        return v.lower()
```

### 4.3 权限控制

#### 4.3.1 RBAC权限模型
```python
# 权限装饰器
from functools import wraps
from fastapi import HTTPException, Depends

def require_permission(permission: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not has_permission(current_user, permission):
                raise HTTPException(status_code=403, detail="权限不足")
            return await func(*args, **kwargs)
        return wrapper
    return decorator

# 使用示例
@app.get("/api/v1/personnel")
@require_permission("personnel:read")
async def get_personnel_list(current_user: User = Depends(get_current_user)):
    # 获取人员列表逻辑
    pass
```

#### 4.3.2 数据级权限
```python
# 数据过滤器
class DataFilter:
    @staticmethod
    def filter_by_organization(query, user: User):
        """按组织架构过滤数据"""
        if user.is_superuser:
            return query
        
        # 获取用户可访问的组织ID列表
        accessible_orgs = get_user_accessible_organizations(user.id)
        return query.filter(Personnel.organization_id.in_(accessible_orgs))
    
    @staticmethod
    def filter_by_project_permission(query, user: User):
        """按项目权限过滤数据"""
        if user.is_superuser:
            return query
        
        # 获取用户可访问的项目ID列表
        accessible_projects = get_user_accessible_projects(user.id)
        return query.filter(Project.id.in_(accessible_projects))
```

### 4.4 安全监控

#### 4.4.1 安全日志
```python
import logging
from datetime import datetime

# 安全日志配置
security_logger = logging.getLogger('security')
security_handler = logging.FileHandler('logs/security.log')
security_formatter = logging.Formatter(
    '%(asctime)s - %(levelname)s - %(message)s'
)
security_handler.setFormatter(security_formatter)
security_logger.addHandler(security_handler)

# 安全事件记录
def log_security_event(event_type: str, user_id: str, details: dict):
    """记录安全事件"""
    security_logger.info({
        'event_type': event_type,
        'user_id': user_id,
        'timestamp': datetime.utcnow().isoformat(),
        'ip_address': get_client_ip(),
        'user_agent': get_user_agent(),
        'details': details
    })

# 使用示例
log_security_event('login_success', user.id, {'username': user.username})
log_security_event('permission_denied', user.id, {'resource': '/api/v1/admin'})
```

#### 4.4.2 异常检测
```python
# 异常行为检测
class SecurityMonitor:
    @staticmethod
    async def detect_suspicious_login(user_id: str, ip_address: str):
        """检测可疑登录"""
        # 检查短时间内多次失败登录
        failed_attempts = await get_failed_login_attempts(user_id, minutes=15)
        if failed_attempts >= 5:
            await trigger_security_alert('multiple_failed_logins', user_id)
        
        # 检查异常IP登录
        is_new_ip = await is_new_login_ip(user_id, ip_address)
        if is_new_ip:
            await trigger_security_alert('new_ip_login', user_id)
    
    @staticmethod
    async def detect_privilege_escalation(user_id: str, action: str):
        """检测权限提升攻击"""
        user_permissions = await get_user_permissions(user_id)
        if action not in user_permissions:
            await trigger_security_alert('privilege_escalation_attempt', user_id)
```

## 5. 部署流程

### 5.1 环境配置

#### 5.1.1 开发环境
```yaml
# docker-compose.dev.yml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - ENV=development
      - DEBUG=true
      - DATABASE_URL=postgresql://user:pass@db:5432/hrscheduling_dev
      - REDIS_URL=redis://redis:6379/0
    volumes:
      - .:/app
    depends_on:
      - db
      - redis
  
  db:
    image: postgres:14
    environment:
      - POSTGRES_DB=hrscheduling_dev
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
  
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

volumes:
  postgres_data:
```

#### 5.1.2 生产环境配置
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    image: hrscheduling-backend:latest
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      - ENV=production
      - DEBUG=false
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
    networks:
      - app-network
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    networks:
      - app-network

networks:
  app-network:
    driver: overlay
```

### 5.2 CI/CD流水线

#### 5.2.1 GitHub Actions配置
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: Run tests
        run: |
          pytest --cov=app tests/
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
  
  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build Docker image
        run: |
          docker build -t hrscheduling-backend:${{ github.sha }} .
          docker tag hrscheduling-backend:${{ github.sha }} hrscheduling-backend:latest
      
      - name: Push to registry
        run: |
          echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
          docker push hrscheduling-backend:${{ github.sha }}
          docker push hrscheduling-backend:latest
  
  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to production
        uses: appleboy/ssh-action@v0.1.5
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_KEY }}
          script: |
            cd /opt/hrscheduling
            docker-compose pull
            docker-compose up -d
            docker system prune -f
```

#### 5.2.2 Dockerfile
```dockerfile
# Dockerfile
FROM python:3.11-slim

# 设置工作目录
WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .

# 安装Python依赖
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 创建非root用户
RUN useradd --create-home --shell /bin/bash app \
    && chown -R app:app /app
USER app

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 5.3 数据库迁移

#### 5.3.1 Alembic配置
```python
# alembic/env.py
from alembic import context
from sqlalchemy import engine_from_config, pool
from app.database import Base
from app.config import settings

# 配置数据库连接
config = context.config
config.set_main_option('sqlalchemy.url', settings.DATABASE_URL)

# 设置目标元数据
target_metadata = Base.metadata

def run_migrations_online():
    """在线模式运行迁移"""
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix='sqlalchemy.',
        poolclass=pool.NullPool,
    )
    
    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata
        )
        
        with context.begin_transaction():
            context.run_migrations()

run_migrations_online()
```

#### 5.3.2 迁移脚本示例
```python
# alembic/versions/001_create_initial_tables.py
"""创建初始表结构

Revision ID: 001
Revises: 
Create Date: 2024-01-01 12:00:00.000000
"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers
revision = '001'
down_revision = None
branch_labels = None
depends_on = None

def upgrade():
    # 创建用户表
    op.create_table('users',
        sa.Column('id', postgresql.UUID(as_uuid=True), nullable=False),
        sa.Column('username', sa.String(length=50), nullable=False),
        sa.Column('email', sa.String(length=100), nullable=False),
        sa.Column('password_hash', sa.String(length=255), nullable=False),
        sa.Column('created_at', sa.TIMESTAMP(timezone=True), nullable=True),
        sa.PrimaryKeyConstraint('id'),
        sa.UniqueConstraint('username'),
        sa.UniqueConstraint('email')
    )
    
    # 创建索引
    op.create_index('idx_users_username', 'users', ['username'])
    op.create_index('idx_users_email', 'users', ['email'])

def downgrade():
    op.drop_index('idx_users_email', table_name='users')
    op.drop_index('idx_users_username', table_name='users')
    op.drop_table('users')
```

### 5.4 监控和运维

#### 5.4.1 Prometheus监控配置
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  - job_name: 'hrscheduling-backend'
    static_configs:
      - targets: ['app:8000']
    metrics_path: '/metrics'
    scrape_interval: 10s
  
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
  
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

#### 5.4.2 告警规则
```yaml
# alert_rules.yml
groups:
  - name: hrscheduling_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"
      
      - alert: DatabaseConnectionHigh
        expr: pg_stat_activity_count > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High database connections"
          description: "Database connections: {{ $value }}"
      
      - alert: AIServiceDown
        expr: up{job="ai-service"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "AI service is down"
          description: "AI service has been down for more than 1 minute"
```

#### 5.4.3 健康检查
```python
# app/health.py
from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session
from app.database import get_db
from app.cache import redis_client
import asyncio

router = APIRouter()

@router.get("/health")
async def health_check():
    """系统健康检查"""
    checks = {
        'status': 'healthy',
        'timestamp': datetime.utcnow().isoformat(),
        'checks': {}
    }
    
    # 数据库连接检查
    try:
        db = next(get_db())
        db.execute('SELECT 1')
        checks['checks']['database'] = 'healthy'
    except Exception as e:
        checks['checks']['database'] = f'unhealthy: {str(e)}'
        checks['status'] = 'unhealthy'
    
    # Redis连接检查
    try:
        await redis_client.ping()
        checks['checks']['redis'] = 'healthy'
    except Exception as e:
        checks['checks']['redis'] = f'unhealthy: {str(e)}'
        checks['status'] = 'unhealthy'
    
    # AI服务检查
    try:
        # 检查AI服务是否可用
        response = await check_ai_service()
        checks['checks']['ai_service'] = 'healthy' if response else 'unhealthy'
    except Exception as e:
        checks['checks']['ai_service'] = f'unhealthy: {str(e)}'
        checks['status'] = 'degraded'  # AI服务异常不影响核心功能
    
    return checks

@router.get("/metrics")
async def metrics():
    """Prometheus指标端点"""
    from prometheus_client import generate_latest, CONTENT_TYPE_LATEST
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

async def check_ai_service() -> bool:
    """检查AI服务状态"""
    try:
        # 发送简单的健康检查请求到AI服务
        import httpx
        async with httpx.AsyncClient() as client:
            response = await client.get('http://ai-service:8001/health', timeout=5)
            return response.status_code == 200
    except:
        return False
```

#### 5.4.4 日志管理
```python
# app/logging_config.py
import logging
import logging.config
from pythonjsonlogger import jsonlogger

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'json': {
            '()': jsonlogger.JsonFormatter,
            'format': '%(asctime)s %(name)s %(levelname)s %(message)s'
        },
        'standard': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
    },
    'handlers': {
        'default': {
            'level': 'INFO',
            'formatter': 'json',
            'class': 'logging.StreamHandler',
        },
        'file': {
            'level': 'INFO',
            'formatter': 'json',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/app.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5,
        },
        'error_file': {
            'level': 'ERROR',
            'formatter': 'json',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/error.log',
            'maxBytes': 10485760,
            'backupCount': 5,
        },
    },
    'loggers': {
        '': {
            'handlers': ['default', 'file'],
            'level': 'INFO',
            'propagate': False
        },
        'app': {
            'handlers': ['default', 'file', 'error_file'],
            'level': 'INFO',
            'propagate': False
        },
        'uvicorn': {
            'handlers': ['default'],
            'level': 'INFO',
            'propagate': False
        },
    }
}

def setup_logging():
    """配置日志系统"""
    logging.config.dictConfig(LOGGING_CONFIG)
```

### 5.5 备份和恢复

#### 5.5.1 数据库备份脚本
```bash
#!/bin/bash
# backup_database.sh

set -e

# 配置变量
DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="hrscheduling"
DB_USER="postgres"
BACKUP_DIR="/opt/backups/database"
DATE=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="${BACKUP_DIR}/hrscheduling_${DATE}.sql"

# 创建备份目录
mkdir -p $BACKUP_DIR

# 执行备份
echo "开始备份数据库..."
pg_dump -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME > $BACKUP_FILE

# 压缩备份文件
gzip $BACKUP_FILE

# 删除7天前的备份
find $BACKUP_DIR -name "*.sql.gz" -mtime +7 -delete

echo "数据库备份完成: ${BACKUP_FILE}.gz"

# 上传到云存储（可选）
# aws s3 cp ${BACKUP_FILE}.gz s3://backup-bucket/database/
```

#### 5.5.2 数据恢复脚本
```bash
#!/bin/bash
# restore_database.sh

set -e

if [ $# -ne 1 ]; then
    echo "使用方法: $0 <backup_file>"
    exit 1
fi

BACKUP_FILE=$1
DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="hrscheduling"
DB_USER="postgres"

# 检查备份文件是否存在
if [ ! -f "$BACKUP_FILE" ]; then
    echo "错误: 备份文件不存在: $BACKUP_FILE"
    exit 1
fi

# 解压备份文件（如果是压缩的）
if [[ $BACKUP_FILE == *.gz ]]; then
    echo "解压备份文件..."
    gunzip -c $BACKUP_FILE > /tmp/restore.sql
    RESTORE_FILE="/tmp/restore.sql"
else
    RESTORE_FILE=$BACKUP_FILE
fi

# 确认恢复操作
read -p "确认要恢复数据库 $DB_NAME 吗？这将覆盖现有数据。(y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "操作已取消"
    exit 1
fi

# 停止应用服务
echo "停止应用服务..."
docker-compose stop app

# 删除现有数据库
echo "删除现有数据库..."
dropdb -h $DB_HOST -p $DB_PORT -U $DB_USER $DB_NAME

# 创建新数据库
echo "创建新数据库..."
createdb -h $DB_HOST -p $DB_PORT -U $DB_USER $DB_NAME

# 恢复数据
echo "恢复数据..."
psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME < $RESTORE_FILE

# 启动应用服务
echo "启动应用服务..."
docker-compose start app

# 清理临时文件
if [ "$RESTORE_FILE" = "/tmp/restore.sql" ]; then
    rm /tmp/restore.sql
fi

echo "数据库恢复完成"
```

## 6. 测试策略

### 6.1 测试框架

#### 6.1.1 单元测试配置
```python
# tests/conftest.py
import pytest
import asyncio
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.main import app
from app.database import Base, get_db
from app.config import settings

# 测试数据库配置
TEST_DATABASE_URL = "postgresql://test:test@localhost:5433/test_hrscheduling"

engine = create_engine(TEST_DATABASE_URL)
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

@pytest.fixture(scope="session")
def event_loop():
    """创建事件循环"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()

@pytest.fixture(scope="function")
def db_session():
    """创建数据库会话"""
    Base.metadata.create_all(bind=engine)
    session = TestingSessionLocal()
    try:
        yield session
    finally:
        session.close()
        Base.metadata.drop_all(bind=engine)

@pytest.fixture(scope="function")
def client(db_session):
    """创建测试客户端"""
    def override_get_db():
        try:
            yield db_session
        finally:
            pass
    
    app.dependency_overrides[get_db] = override_get_db
    with TestClient(app) as test_client:
        yield test_client
    app.dependency_overrides.clear()

@pytest.fixture
def test_user(db_session):
    """创建测试用户"""
    from app.models import User
    from app.auth import get_password_hash
    
    user = User(
        username="testuser",
        email="test@example.com",
        password_hash=get_password_hash("testpass123")
    )
    db_session.add(user)
    db_session.commit()
    db_session.refresh(user)
    return user
```

#### 6.1.2 API测试示例
```python
# tests/test_personnel_api.py
import pytest
from fastapi import status

class TestPersonnelAPI:
    """人员管理API测试"""
    
    def test_create_personnel_success(self, client, test_user):
        """测试创建人员成功"""
        personnel_data = {
            "name": "张三",
            "employee_id": "EMP001",
            "email": "zhangsan@example.com",
            "phone": "13800138000",
            "position": "园林工程师",
            "skills": [
                {
                    "skill_type": "园林设计",
                    "skill_level": "高级",
                    "certification": "园林工程师证书"
                }
            ]
        }
        
        response = client.post("/api/v1/personnel", json=personnel_data)
        
        assert response.status_code == status.HTTP_201_CREATED
        data = response.json()
        assert data["data"]["name"] == "张三"
        assert data["data"]["employee_id"] == "EMP001"
    
    def test_create_personnel_duplicate_employee_id(self, client, test_user):
        """测试创建重复员工ID的人员"""
        personnel_data = {
            "name": "张三",
            "employee_id": "EMP001",
            "email": "zhangsan@example.com"
        }
        
        # 第一次创建
        client.post("/api/v1/personnel", json=personnel_data)
        
        # 第二次创建相同员工ID
        personnel_data["name"] = "李四"
        personnel_data["email"] = "lisi@example.com"
        response = client.post("/api/v1/personnel", json=personnel_data)
        
        assert response.status_code == status.HTTP_409_CONFLICT
    
    def test_get_personnel_list(self, client, test_user):
        """测试获取人员列表"""
        response = client.get("/api/v1/personnel")
        
        assert response.status_code == status.HTTP_200_OK
        data = response.json()
        assert "data" in data
        assert "items" in data["data"]
        assert "total" in data["data"]
    
    def test_get_personnel_by_id(self, client, test_user, db_session):
        """测试根据ID获取人员信息"""
        from app.models import Personnel
        
        # 创建测试人员
        personnel = Personnel(
            name="张三",
            employee_id="EMP001",
            email="zhangsan@example.com"
        )
        db_session.add(personnel)
        db_session.commit()
        
        response = client.get(f"/api/v1/personnel/{personnel.id}")
        
        assert response.status_code == status.HTTP_200_OK
        data = response.json()
        assert data["data"]["name"] == "张三"
    
    def test_update_personnel(self, client, test_user, db_session):
        """测试更新人员信息"""
        from app.models import Personnel
        
        # 创建测试人员
        personnel = Personnel(
            name="张三",
            employee_id="EMP001",
            email="zhangsan@example.com"
        )
        db_session.add(personnel)
        db_session.commit()
        
        update_data = {
            "name": "张三丰",
            "phone": "13800138001"
        }
        
        response = client.put(f"/api/v1/personnel/{personnel.id}", json=update_data)
        
        assert response.status_code == status.HTTP_200_OK
        data = response.json()
        assert data["data"]["name"] == "张三丰"
        assert data["data"]["phone"] == "13800138001"
```

### 6.2 集成测试

#### 6.2.1 调度流程集成测试
```python
# tests/test_scheduling_integration.py
import pytest
from datetime import date, time

class TestSchedulingIntegration:
    """调度流程集成测试"""
    
    @pytest.fixture
    def setup_test_data(self, db_session):
        """设置测试数据"""
        from app.models import Personnel, Project, Client
        
        # 创建客户
        client = Client(name="测试客户", code="CLIENT001")
        db_session.add(client)
        
        # 创建项目
        project = Project(
            name="测试项目",
            code="PROJ001",
            client_id=client.id,
            start_date=date(2024, 1, 1),
            end_date=date(2024, 12, 31),
            requirements={
                "personnel_count": 5,
                "skill_requirements": [
                    {"skill_type": "园林设计", "skill_level": "高级", "required_count": 2}
                ]
            }
        )
        db_session.add(project)
        
        # 创建人员
        personnel_list = []
        for i in range(10):
            personnel = Personnel(
                name=f"员工{i+1}",
                employee_id=f"EMP{i+1:03d}",
                email=f"emp{i+1}@example.com",
                skills=[
                    {
                        "skill_type": "园林设计",
                        "skill_level": "高级" if i < 3 else "中级",
                        "certification": "园林工程师证书"
                    }
                ]
            )
            personnel_list.append(personnel)
            db_session.add(personnel)
        
        db_session.commit()
        return {
            "client": client,
            "project": project,
            "personnel_list": personnel_list
        }
    
    def test_ai_matching_workflow(self, client, setup_test_data):
        """测试AI匹配工作流程"""
        project = setup_test_data["project"]
        
        # 1. 发起AI匹配请求
        match_request = {
            "project_id": str(project.id),
            "requirements": {
                "skill_types": ["园林设计"],
                "skill_levels": ["高级"],
                "personnel_count": 2,
                "time_range": {
                    "start_date": "2024-01-01",
                    "end_date": "2024-01-31"
                }
            }
        }
        
        response = client.post("/api/v1/schedules/ai-match", json=match_request)
        assert response.status_code == 200
        
        match_results = response.json()["data"]
        assert len(match_results["recommendations"]) > 0
        
        # 2. 验证匹配结果
        for recommendation in match_results["recommendations"]:
            assert recommendation["match_score"] > 0
            assert "personnel_id" in recommendation
            assert "match_factors" in recommendation
        
        # 3. 创建调度记录
        best_match = match_results["recommendations"][0]
        schedule_data = {
            "project_id": str(project.id),
            "personnel_id": best_match["personnel_id"],
            "schedule_date": "2024-01-15",
            "work_hours": {
                "start": "08:00",
                "end": "17:00"
            },
            "role": "园林设计师"
        }
        
        response = client.post("/api/v1/schedules", json=schedule_data)
        assert response.status_code == 201
        
        # 4. 验证调度记录创建成功
        schedule = response.json()["data"]
        assert schedule["project_id"] == str(project.id)
        assert schedule["personnel_id"] == best_match["personnel_id"]
    
    def test_conflict_detection(self, client, setup_test_data):
        """测试冲突检测"""
        project = setup_test_data["project"]
        personnel = setup_test_data["personnel_list"][0]
        
        # 1. 创建第一个调度记录
        schedule_data = {
            "project_id": str(project.id),
            "personnel_id": str(personnel.id),
            "schedule_date": "2024-01-15",
            "work_hours": {
                "start": "08:00",
                "end": "17:00"
            }
        }
        
        response = client.post("/api/v1/schedules", json=schedule_data)
        assert response.status_code == 201
        
        # 2. 尝试创建冲突的调度记录
        conflicting_schedule = {
            "project_id": str(project.id),
            "personnel_id": str(personnel.id),
            "schedule_date": "2024-01-15",
            "work_hours": {
                "start": "09:00",
                "end": "18:00"
            }
        }
        
        response = client.post("/api/v1/schedules", json=conflicting_schedule)
        assert response.status_code == 409  # 冲突错误
        
        # 3. 检查冲突检测API
        response = client.get(
            f"/api/v1/schedules/conflicts?personnel_id={personnel.id}&date_range=2024-01-01,2024-01-31"
        )
        assert response.status_code == 200
        
        conflicts = response.json()["data"]
        assert len(conflicts) >= 0  # 应该检测到潜在冲突
```

### 6.3 性能测试

#### 6.3.1 负载测试配置
```python
# tests/performance/locustfile.py
from locust import HttpUser, task, between
import random
import json

class HRSchedulingUser(HttpUser):
    wait_time = between(1, 3)
    
    def on_start(self):
        """用户开始时的初始化"""
        # 登录获取token
        response = self.client.post("/api/v1/auth/login", json={
            "username": "testuser",
            "password": "testpass123"
        })
        
        if response.status_code == 200:
            self.token = response.json()["data"]["access_token"]
            self.headers = {"Authorization": f"Bearer {self.token}"}
        else:
            self.headers = {}
    
    @task(3)
    def get_personnel_list(self):
        """获取人员列表"""
        self.client.get("/api/v1/personnel", headers=self.headers)
    
    @task(2)
    def get_project_list(self):
        """获取项目列表"""
        self.client.get("/api/v1/projects", headers=self.headers)
    
    @task(2)
    def get_schedule_list(self):
        """获取调度列表"""
        self.client.get("/api/v1/schedules", headers=self.headers)
    
    @task(1)
    def ai_matching(self):
        """AI匹配测试"""
        match_request = {
            "project_id": "test-project-id",
            "requirements": {
                "skill_types": ["园林设计"],
                "skill_levels": ["高级"],
                "personnel_count": random.randint(1, 5),
                "time_range": {
                    "start_date": "2024-01-01",
                    "end_date": "2024-01-31"
                }
            }
        }
        
        self.client.post(
            "/api/v1/schedules/ai-match",
            json=match_request,
            headers=self.headers
        )
    
    @task(1)
    def create_schedule(self):
        """创建调度记录"""
        schedule_data = {
            "project_id": "test-project-id",
            "personnel_id": "test-personnel-id",
            "schedule_date": "2024-01-15",
            "work_hours": {
                "start": "08:00",
                "end": "17:00"
            }
        }
        
        self.client.post(
            "/api/v1/schedules",
            json=schedule_data,
            headers=self.headers
        )
```

#### 6.3.2 数据库性能测试
```python
# tests/performance/test_database_performance.py
import pytest
import time
from sqlalchemy import text

class TestDatabasePerformance:
    """数据库性能测试"""
    
    def test_personnel_query_performance(self, db_session):
        """测试人员查询性能"""
        # 创建大量测试数据
        self.create_test_personnel(db_session, 1000)
        
        # 测试简单查询性能
        start_time = time.time()
        result = db_session.execute(
            text("SELECT * FROM personnel WHERE status = 'active' LIMIT 20")
        ).fetchall()
        query_time = time.time() - start_time
        
        assert len(result) <= 20
        assert query_time < 0.1  # 查询时间应小于100ms
    
    def test_complex_schedule_query_performance(self, db_session):
        """测试复杂调度查询性能"""
        # 创建测试数据
        self.create_test_schedules(db_session, 5000)
        
        # 测试复杂查询性能
        start_time = time.time()
        result = db_session.execute(text("""
            SELECT p.name, pr.name as project_name, s.schedule_date
            FROM schedules s
            JOIN personnel p ON s.personnel_id = p.id
            JOIN projects pr ON s.project_id = pr.id
            WHERE s.schedule_date BETWEEN '2024-01-01' AND '2024-01-31'
            AND s.status = 'approved'
            ORDER BY s.schedule_date
            LIMIT 50
        """)).fetchall()
        query_time = time.time() - start_time
        
        assert len(result) <= 50
        assert query_time < 0.5  # 复杂查询时间应小于500ms
    
    def create_test_personnel(self, db_session, count):
        """创建测试人员数据"""
        from app.models import Personnel
        
        personnel_list = []
        for i in range(count):
            personnel = Personnel(
                name=f"测试员工{i}",
                employee_id=f"TEST{i:06d}",
                email=f"test{i}@example.com",
                status="active"
            )
            personnel_list.append(personnel)
        
        db_session.bulk_save_objects(personnel_list)
        db_session.commit()
    
    def create_test_schedules(self, db_session, count):
        """创建测试调度数据"""
        # 实现创建大量调度测试数据的逻辑
        pass
```

## 7. 总结

本文档详细描述了人力资源调度系统的后端技术架构和实现方案，涵盖了以下核心内容：

### 7.1 技术架构特点
- **微服务架构**：模块化设计，便于扩展和维护
- **容器化部署**：Docker + Kubernetes，支持弹性伸缩
- **高性能技术栈**：FastAPI + PostgreSQL + Redis，确保系统响应速度
- **AI算法集成**：内置机器学习算法，提供智能调度能力

### 7.2 核心功能实现
- **智能调度管理**：基于AI算法的人员匹配和调度优化
- **风险管控系统**：实时监控、预警和应急响应机制
- **数据分析平台**：配置评估、趋势预测和决策支持
- **完整的API体系**：RESTful接口设计，支持前端和第三方集成

### 7.3 安全和运维保障
- **多层安全防护**：认证授权、数据加密、访问控制
- **完善的监控体系**：Prometheus + Grafana，实时监控系统状态
- **自动化部署**：CI/CD流水线，确保部署质量和效率
- **备份恢复机制**：数据安全和业务连续性保障

### 7.4 质量保证
- **全面的测试策略**：单元测试、集成测试、性能测试
- **代码质量控制**：代码审查、静态分析、覆盖率检查
- **性能优化**：数据库优化、缓存策略、查询优化

本技术文档为系统开发、部署和运维提供了完整的技术指导，确保系统能够稳定、高效地服务于园林绿化施工公司的人力资源调度管理需求。

---

**文档维护说明**：
- 本文档应随着系统开发进展持续更新
- 重要技术变更需要及时反映到文档中
- 建议定期审查文档内容的准确性和完整性
- 新团队成员应首先阅读本文档以了解系统架构